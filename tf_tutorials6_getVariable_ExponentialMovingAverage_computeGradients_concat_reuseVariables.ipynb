{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cov1/var1:0\n",
      "cov1/var2:0\n",
      "cov2/var3:0\n",
      "var4:0\n",
      "cov1/var1:0\n",
      "cov1/var2:0\n",
      "cov2/var3:0\n",
      "var4:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.variable_scope('cov1') as scope:\n",
    "    var1 = tf.Variable(2.0,name='var1')\n",
    "    var2 = tf.get_variable(name='var2',initializer=2.1)\n",
    "    print(var1.name)\n",
    "    print(var2.name)\n",
    "with tf.name_scope('cov2')as scope:\n",
    "    var3 = tf.Variable(2.22,name='var3')\n",
    "    var4 = tf.get_variable(name='var4',initializer=2.33)\n",
    "    print(var3.name)\n",
    "    print(var4.name)\n",
    "print(var1.name)\n",
    "print(var2.name)\n",
    "print(var3.name)\n",
    "print(var4.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var1:0\n",
      "my_scope1/var2:0\n",
      "my_scope1/Add:0\n",
      "\n",
      "my_scope2/var1:0\n",
      "my_scope2/var2:0\n",
      "my_scope2/Add:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"功能是在代码块内显式创建的变量都会带上scope前缀（如上面例子中的a）\n",
    "  差别是对 tf.get_variable() 函数的作用是一个会自动添加前缀，一个不会添加前缀\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "with tf.name_scope(\"my_scope1\"):\n",
    "    v1 = tf.get_variable(\"var1\", [1], dtype=tf.float32)\n",
    "    v2 = tf.Variable(1, name=\"var2\", dtype=tf.float32)\n",
    "    a = tf.add(v1, v2)\n",
    "\n",
    "print(v1.name)  # var1:0\n",
    "print(v2.name)  # my_scope/var2:0\n",
    "print(a.name)   # my_scope/Add:0\n",
    "\n",
    "print()\n",
    "\n",
    "with tf.variable_scope(\"my_scope2\"):\n",
    "    v1 = tf.get_variable(\"var1\", [1], dtype=tf.float32)\n",
    "    v2 = tf.Variable(1, name=\"var2\", dtype=tf.float32)\n",
    "    a = tf.add(v1, v2)\n",
    "\n",
    "print(v1.name)  # my_scope/var1:0\n",
    "print(v2.name)  # my_scope/var2:0\n",
    "print(a.name)   # my_scope/Add:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6\n",
      "3\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"每个Session对Variable的管理是独立的，所以同一个Variable在不同的Session中可以有不同的值\n",
    "   如果运行自己创建的graph，一定要把它传递给tf.Session的graph参数\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "sess1 = tf.Session()\n",
    "sess2 = tf.Session()\n",
    "\n",
    "graph1 = tf.Graph()\n",
    "graph2 = tf.Graph()\n",
    "\n",
    "with graph1.as_default():\n",
    "    a = tf.add(1,2)\n",
    "    with tf.name_scope('haha')as scope:\n",
    "        var1 = tf.Variable(4.0,name='var1')\n",
    "with graph2.as_default():\n",
    "    b = tf.multiply(2,3)\n",
    "\n",
    "sess1 = tf.Session(graph=graph1)\n",
    "print(sess1.run(a))\n",
    "\n",
    "sess1 = tf.Session(graph=graph2)\n",
    "print(sess1.run(b))\n",
    "\n",
    "a = tf.constant(3)\n",
    "print(sess2.run(a))\n",
    "\n",
    "v1 = tf.global_variables()\n",
    "print(v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "60\n",
      "(6, 4, 4, 5)\n",
      "[[[[   4060.    4162.    4264.    4366.    4468.]\n",
      "   [   5050.    5188.    5326.    5464.    5602.]\n",
      "   [   6040.    6214.    6388.    6562.    6736.]\n",
      "   [   2480.    2576.    2672.    2768.    2864.]]\n",
      "\n",
      "  [[   8020.    8266.    8512.    8758.    9004.]\n",
      "   [   9010.    9292.    9574.    9856.   10138.]\n",
      "   [  10000.   10318.   10636.   10954.   11272.]\n",
      "   [   3920.    4088.    4256.    4424.    4592.]]\n",
      "\n",
      "  [[  11980.   12370.   12760.   13150.   13540.]\n",
      "   [  12970.   13396.   13822.   14248.   14674.]\n",
      "   [  13960.   14422.   14884.   15346.   15808.]\n",
      "   [   5360.    5600.    5840.    6080.    6320.]]\n",
      "\n",
      "  [[   2975.    3206.    3437.    3668.    3899.]\n",
      "   [   3200.    3449.    3698.    3947.    4196.]\n",
      "   [   3425.    3692.    3959.    4226.    4493.]\n",
      "   [    700.     838.     976.    1114.    1252.]]]\n",
      "\n",
      "\n",
      " [[[  19900.   20578.   21256.   21934.   22612.]\n",
      "   [  20890.   21604.   22318.   23032.   23746.]\n",
      "   [  21880.   22630.   23380.   24130.   24880.]\n",
      "   [   8240.    8624.    9008.    9392.    9776.]]\n",
      "\n",
      "  [[  23860.   24682.   25504.   26326.   27148.]\n",
      "   [  24850.   25708.   26566.   27424.   28282.]\n",
      "   [  25840.   26734.   27628.   28522.   29416.]\n",
      "   [   9680.   10136.   10592.   11048.   11504.]]\n",
      "\n",
      "  [[  27820.   28786.   29752.   30718.   31684.]\n",
      "   [  28810.   29812.   30814.   31816.   32818.]\n",
      "   [  29800.   30838.   31876.   32914.   33952.]\n",
      "   [  11120.   11648.   12176.   12704.   13232.]]\n",
      "\n",
      "  [[   6575.    7094.    7613.    8132.    8651.]\n",
      "   [   6800.    7337.    7874.    8411.    8948.]\n",
      "   [   7025.    7580.    8135.    8690.    9245.]\n",
      "   [   1420.    1702.    1984.    2266.    2548.]]]\n",
      "\n",
      "\n",
      " [[[  35740.   36994.   38248.   39502.   40756.]\n",
      "   [  36730.   38020.   39310.   40600.   41890.]\n",
      "   [  37720.   39046.   40372.   41698.   43024.]\n",
      "   [  14000.   14672.   15344.   16016.   16688.]]\n",
      "\n",
      "  [[  39700.   41098.   42496.   43894.   45292.]\n",
      "   [  40690.   42124.   43558.   44992.   46426.]\n",
      "   [  41680.   43150.   44620.   46090.   47560.]\n",
      "   [  15440.   16184.   16928.   17672.   18416.]]\n",
      "\n",
      "  [[  43660.   45202.   46744.   48286.   49828.]\n",
      "   [  44650.   46228.   47806.   49384.   50962.]\n",
      "   [  45640.   47254.   48868.   50482.   52096.]\n",
      "   [  16880.   17696.   18512.   19328.   20144.]]\n",
      "\n",
      "  [[  10175.   10982.   11789.   12596.   13403.]\n",
      "   [  10400.   11225.   12050.   12875.   13700.]\n",
      "   [  10625.   11468.   12311.   13154.   13997.]\n",
      "   [   2140.    2566.    2992.    3418.    3844.]]]\n",
      "\n",
      "\n",
      " [[[  51580.   53410.   55240.   57070.   58900.]\n",
      "   [  52570.   54436.   56302.   58168.   60034.]\n",
      "   [  53560.   55462.   57364.   59266.   61168.]\n",
      "   [  19760.   20720.   21680.   22640.   23600.]]\n",
      "\n",
      "  [[  55540.   57514.   59488.   61462.   63436.]\n",
      "   [  56530.   58540.   60550.   62560.   64570.]\n",
      "   [  57520.   59566.   61612.   63658.   65704.]\n",
      "   [  21200.   22232.   23264.   24296.   25328.]]\n",
      "\n",
      "  [[  59500.   61618.   63736.   65854.   67972.]\n",
      "   [  60490.   62644.   64798.   66952.   69106.]\n",
      "   [  61480.   63670.   65860.   68050.   70240.]\n",
      "   [  22640.   23744.   24848.   25952.   27056.]]\n",
      "\n",
      "  [[  13775.   14870.   15965.   17060.   18155.]\n",
      "   [  14000.   15113.   16226.   17339.   18452.]\n",
      "   [  14225.   15356.   16487.   17618.   18749.]\n",
      "   [   2860.    3430.    4000.    4570.    5140.]]]\n",
      "\n",
      "\n",
      " [[[  67420.   69826.   72232.   74638.   77044.]\n",
      "   [  68410.   70852.   73294.   75736.   78178.]\n",
      "   [  69400.   71878.   74356.   76834.   79312.]\n",
      "   [  25520.   26768.   28016.   29264.   30512.]]\n",
      "\n",
      "  [[  71380.   73930.   76480.   79030.   81580.]\n",
      "   [  72370.   74956.   77542.   80128.   82714.]\n",
      "   [  73360.   75982.   78604.   81226.   83848.]\n",
      "   [  26960.   28280.   29600.   30920.   32240.]]\n",
      "\n",
      "  [[  75340.   78034.   80728.   83422.   86116.]\n",
      "   [  76330.   79060.   81790.   84520.   87250.]\n",
      "   [  77320.   80086.   82852.   85618.   88384.]\n",
      "   [  28400.   29792.   31184.   32576.   33968.]]\n",
      "\n",
      "  [[  17375.   18758.   20141.   21524.   22907.]\n",
      "   [  17600.   19001.   20402.   21803.   23204.]\n",
      "   [  17825.   19244.   20663.   22082.   23501.]\n",
      "   [   3580.    4294.    5008.    5722.    6436.]]]\n",
      "\n",
      "\n",
      " [[[  83260.   86242.   89224.   92206.   95188.]\n",
      "   [  84250.   87268.   90286.   93304.   96322.]\n",
      "   [  85240.   88294.   91348.   94402.   97456.]\n",
      "   [  31280.   32816.   34352.   35888.   37424.]]\n",
      "\n",
      "  [[  87220.   90346.   93472.   96598.   99724.]\n",
      "   [  88210.   91372.   94534.   97696.  100858.]\n",
      "   [  89200.   92398.   95596.   98794.  101992.]\n",
      "   [  32720.   34328.   35936.   37544.   39152.]]\n",
      "\n",
      "  [[  91180.   94450.   97720.  100990.  104260.]\n",
      "   [  92170.   95476.   98782.  102088.  105394.]\n",
      "   [  93160.   96502.   99844.  103186.  106528.]\n",
      "   [  34160.   35840.   37520.   39200.   40880.]]\n",
      "\n",
      "  [[  20975.   22646.   24317.   25988.   27659.]\n",
      "   [  21200.   22889.   24578.   26267.   27956.]\n",
      "   [  21425.   23132.   24839.   26546.   28253.]\n",
      "   [   4300.    5158.    6016.    6874.    7732.]]]]\n"
     ]
    }
   ],
   "source": [
    "##############conv2d\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(6*4*4*3)\n",
    "print(2*2*3*5)\n",
    "\n",
    "x = np.arange(288,dtype = np.float32).reshape([6,4,4,3])\n",
    "weight = np.arange(60,dtype = np.float32).reshape([2,2,3,5])\n",
    "sess = tf.InteractiveSession()\n",
    "conv1 = tf.nn.conv2d(x,weight,[1,1,1,1],padding = 'SAME')\n",
    "print(conv1.get_shape())\n",
    "print(conv1.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36864\n",
      "(1, 12, 12, 64)\n",
      "<bound method Tensor.get_shape of <tf.Tensor 'LRN:0' shape=(1, 12, 12, 64) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "##############lrn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(24*24*64)\n",
    "x = np.arange(36864,dtype = np.float32).reshape([1,24,24,64])\n",
    "sess = tf.InteractiveSession()\n",
    "p = tf.nn.max_pool(x,ksize=[1,3,3,1],strides =[1,2,2,1],padding = 'SAME')\n",
    "print(p.get_shape())\n",
    "\n",
    "n = tf.nn.lrn(p,4,bias=1.0,alpha = 0.001/9.0,beta=0.75)\n",
    "print(n.get_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.5\n",
      "13.5\n"
     ]
    }
   ],
   "source": [
    "##############l2_loss\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "a = np.array([3,3,3],dtype=np.float32)\n",
    "sess = tf.InteractiveSession()\n",
    "b = tf.nn.l2_loss(a)\n",
    "print(b.eval())\n",
    "\n",
    "print(3*9/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "========\n",
      "1.29\n",
      "========\n",
      "1.561\n",
      "========\n"
     ]
    }
   ],
   "source": [
    "############## tf.train.ExponentialMovingAverage(0.9)\n",
    "import tensorflow as tf\n",
    "w = tf.Variable(1.0)\n",
    "ema = tf.train.ExponentialMovingAverage(0.9)\n",
    "update = tf.assign_add(w, 1.0)\n",
    "\n",
    "with tf.control_dependencies([update]):\n",
    "    #返回一个op,这个op用来更新moving_average\n",
    "    ema_op = ema.apply([w])#这句和下面那句不能调换顺序\n",
    "# 此op用来返回当前的moving_average\n",
    "ema_val = ema.average(w)#参数不能是list，有点蛋疼\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(3):\n",
    "        sess.run(ema_op)\n",
    "        print(sess.run(ema_val))\n",
    "        print('========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "############## tf.train.ExponentialMovingAverage(0.9)\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "w0 = tf.Variable(3.0)\n",
    "w = tf.Variable(1.0)\n",
    "\n",
    "aver = tf.train.ExponentialMovingAverage(0.9)\n",
    "aver_op = aver.apply([w0,w])\n",
    "with tf.control_dependencies([aver_op]):\n",
    "    w = tf.identity(w)\n",
    "tf.global_variables_initializer().run()\n",
    "print(w.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([11, 33, 22])\n"
     ]
    }
   ],
   "source": [
    "############## dict.values()\n",
    "dict = {'1':11,'2':22,'3':33}\n",
    "vars = dict.values()\n",
    "print(vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3.0, 3.0), (4444.0, 54634.0), (5.0, 8.0)]\n",
      "[(<tf.Tensor 'gradients_6/mul_28_grad/tuple/control_dependency_1:0' shape=() dtype=float32>, <tf.Variable 'Variable_28:0' shape=() dtype=float32_ref>), (<tf.Tensor 'gradients_6/mul_29_grad/tuple/control_dependency_1:0' shape=() dtype=float32>, <tf.Variable 'Variable_29:0' shape=() dtype=float32_ref>), (<tf.Tensor 'gradients_6/mul_30_grad/tuple/control_dependency_1:0' shape=() dtype=float32>, <tf.Variable 'Variable_30:0' shape=() dtype=float32_ref>)]\n"
     ]
    }
   ],
   "source": [
    "############## opt.compute_gradients\n",
    "import tensorflow as tf\n",
    "x = tf.Variable(3.0,dtype=tf.float32)\n",
    "y = tf.Variable(54634.0,dtype=tf.float32)\n",
    "z = tf.Variable(8.0,dtype=tf.float32)\n",
    "t = 3*x + 4444*y +5*z\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "opt = tf.train.AdamOptimizer(1e-4)\n",
    "gradient = opt.compute_gradients(t,[x,y,z])\n",
    "print(sess.run(gradient))\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 111]\n",
      "[1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "############## tf.concat\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "l = [1,2,3,4,5,6,7,8,9]\n",
    "l.append(111)\n",
    "print(l)\n",
    "print(sess.run(tf.concat([list],axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------conv1 weights haha---------------\n",
      "-------------conv1 weights haha---------------\n"
     ]
    }
   ],
   "source": [
    "############## tf.get_variable_scope().reuse_variables()\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "def run():\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "            weights = tf.get_variable('weights', \n",
    "                                      shape = [5,5,1,32],  #[3,3,3,16],\n",
    "                                      dtype = tf.float32, \n",
    "                                      initializer=tf.truncated_normal_initializer(stddev=0.1,dtype=tf.float32))\n",
    "            print('-------------conv1 weights haha---------------')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "run()\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
